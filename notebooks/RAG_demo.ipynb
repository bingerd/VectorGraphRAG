{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cec1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.text_splitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.text_splitter'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e0d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.7.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.18.4)\n",
      "Requirement already satisfied: anyio in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/bing/Repositories/KG VectorDB RAG/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f04ece94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760531627.785267 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531627.786294 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531628.356233 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531628.357249 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531635.847730 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531635.849580 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts {\n",
      "  contexts {\n",
      "    source_uri: \"gs://rag-corpus-bing/documents/XD Team Update - September 2025.pdf\"\n",
      "    text: \"A new avenue \\r\\nto collaborate is the DPP program. Colleagues that get onboarded through the program can \\r\\nbe selected by Databricks to help their customers. \\r\\nThere are various specializations and levels, from Data Engineering to AI/ML, from \\r\\nArchitects to Solution Consultants. Currently, Databricks is asking us to propose Sr. GenAI \\r\\nEngineers, and Caio have started the interview process. \\r\\nOf the colleagues already onboarded, Victor K has started at ASML through the DPP \\r\\nprogram, while Cor has started at Allianz. \\r\\nWe plan to continue to onboard new colleagues and keep on growing the partnership \\r\\nthrough regular meetings with Databricks Sales and Databricks partner managers in \\r\\nEurope, while also increasing our pool of certified consultants & Databricks champions \\r\\n(which counts towards our partner status: weâ€™re currently Elite, with 83 certified colleagues \\r\\n10and 5 champions!). If you want to get certified as well, we have some vouchers waiting for \\r\\nyou! \\r\\nOn top of that, our Xebia Base Databricks platform has been recognized as an approved \\r\\nsolution by them, meaning they can start offering and pitching it to their customers \\r\\ndirectly. \\r\\nSome extra news and interesting bits: \\r\\nâ€¢ We secured Free $10K Databricks credits for Innovation on GCP\\r\\nâ€¢ Xebia generates USD 6M/year Databricks consumption worldwide \\r\\nâ€¢ We submitted 8 case studies to Databricks\\r\\no TBAuctions\\' New Data Platform Cures Growing Pains\\r\\no Pioneering Grocery Chain Improves Prediction Accuracy by 5%\\r\\no Vattenfall Empowers Customer Sustainability With Data Product - Xebia\\r\\no AXA Boosts Growth & Productivity with MLOps | Xebia\\r\\no The \\\"Secret Ingredient\\\" Making Paula\\'s Choice Customers Glow: Data\\r\\no Quby Uses Data-Driven Apps to Reduce Energy Waste - Xebia\\r\\no Clay Solutions: A New Data Platform to Improve Customer Service\\r\\no Insify Leverages Data to Insure Small EntrepreneursÂ Â \\r\\nâ€¢ We are planning a workshop with them in Amsterdam â€“ Planned for January â€˜26 \\r\\nSupport Office \\r\\nOffice support updates \\r\\nâ€¢ From October, Femke will be working full-time for Xebia Data.\"\n",
      "    source_display_name: \"XD Team Update - September 2025.pdf\"\n",
      "    score: 0.3196633290859433\n",
      "    chunk {\n",
      "      text: \"A new avenue \\r\\nto collaborate is the DPP program. Colleagues that get onboarded through the program can \\r\\nbe selected by Databricks to help their customers. \\r\\nThere are various specializations and levels, from Data Engineering to AI/ML, from \\r\\nArchitects to Solution Consultants. Currently, Databricks is asking us to propose Sr. GenAI \\r\\nEngineers, and Caio have started the interview process. \\r\\nOf the colleagues already onboarded, Victor K has started at ASML through the DPP \\r\\nprogram, while Cor has started at Allianz. \\r\\nWe plan to continue to onboard new colleagues and keep on growing the partnership \\r\\nthrough regular meetings with Databricks Sales and Databricks partner managers in \\r\\nEurope, while also increasing our pool of certified consultants & Databricks champions \\r\\n(which counts towards our partner status: weâ€™re currently Elite, with 83 certified colleagues \\r\\n10and 5 champions!). If you want to get certified as well, we have some vouchers waiting for \\r\\nyou! \\r\\nOn top of that, our Xebia Base Databricks platform has been recognized as an approved \\r\\nsolution by them, meaning they can start offering and pitching it to their customers \\r\\ndirectly. \\r\\nSome extra news and interesting bits: \\r\\nâ€¢ We secured Free $10K Databricks credits for Innovation on GCP\\r\\nâ€¢ Xebia generates USD 6M/year Databricks consumption worldwide \\r\\nâ€¢ We submitted 8 case studies to Databricks\\r\\no TBAuctions\\' New Data Platform Cures Growing Pains\\r\\no Pioneering Grocery Chain Improves Prediction Accuracy by 5%\\r\\no Vattenfall Empowers Customer Sustainability With Data Product - Xebia\\r\\no AXA Boosts Growth & Productivity with MLOps | Xebia\\r\\no The \\\"Secret Ingredient\\\" Making Paula\\'s Choice Customers Glow: Data\\r\\no Quby Uses Data-Driven Apps to Reduce Energy Waste - Xebia\\r\\no Clay Solutions: A New Data Platform to Improve Customer Service\\r\\no Insify Leverages Data to Insure Small EntrepreneursÂ Â \\r\\nâ€¢ We are planning a workshop with them in Amsterdam â€“ Planned for January â€˜26 \\r\\nSupport Office \\r\\nOffice support updates \\r\\nâ€¢ From October, Femke will be working full-time for Xebia Data.\"\n",
      "      page_span {\n",
      "        first_page: 10\n",
      "        last_page: 11\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    source_uri: \"gs://rag-corpus-bing/documents/XD Team Update - September 2025.pdf\"\n",
      "    text: \"â€¢ Making the Right Choice: Flink or Kafka Streams? by Juliusz NadbereÅ¼ny. \\r\\nâ€¢ Setting up a local Langfuse server with Kubernetes to trace Agentic systems by \\r\\nJetze. \\r\\nâ€¢ Five Python Tips You Wonâ€™t Find in Most Curriculums by Lucy. \\r\\nâ€¢ Why Your Team Doesn\\'t Trust AI and How You Can Change It by Sjoerd. \\r\\nCTO Office \\r\\nAs you all know, we have been hiring for a new role with Xebia Data: the Field CTO \\r\\nrole. The Field CTO will focus on engaging with clients, providing architectural \\r\\nguidance, and supporting our sales team in presales activities.\\r\\nWe are happy to announce the first group of Field CTOs:\\r\\nâ€¢ Cor Zuurmond \\r\\nâ€¢ Jasper Ginn \\r\\nâ€¢ Julian de Ruiter \\r\\nâ€¢ Padraic Slattery \\r\\nâ€¢ Rogier van der Geer \\r\\nPadraic Slattery will be leading the group with my support. Once the group has \\r\\nsettled in, we will be hosting an XKE to discuss how the Field CTO role is being filled, \\r\\nthe initial challenges we encountered, and any other learnings.\\r\\nWe wish the group well in their new role, good luck!\\r\\nMotherduck update \\r\\nWe are happy to announce that we will be become a partner of Motherduck. \\r\\nMotherduck will launch the EU service next month and we will be included as an launching \\r\\npartner. Together with them we will host a webinar, create a blog post and start sharing \\r\\nopportunities. \\r\\nThanks to Tim W for managing the sales effort around the partnership! \\r\\nDatabricks update \\r\\nA general update for our Databricks partnership and a look forward to end of year. Thanks \\r\\nCor! \\r\\nWe have more traction with landing projects together or through Databricks. A new avenue \\r\\nto collaborate is the DPP program. Colleagues that get onboarded through the program can \\r\\nbe selected by Databricks to help their customers. \\r\\nThere are various specializations and levels, from Data Engineering to AI/ML, from \\r\\nArchitects to Solution Consultants. Currently, Databricks is asking us to propose Sr. GenAI \\r\\nEngineers, and Caio have started the interview process.\"\n",
      "    source_display_name: \"XD Team Update - September 2025.pdf\"\n",
      "    score: 0.37285791259413525\n",
      "    chunk {\n",
      "      text: \"â€¢ Making the Right Choice: Flink or Kafka Streams? by Juliusz NadbereÅ¼ny. \\r\\nâ€¢ Setting up a local Langfuse server with Kubernetes to trace Agentic systems by \\r\\nJetze. \\r\\nâ€¢ Five Python Tips You Wonâ€™t Find in Most Curriculums by Lucy. \\r\\nâ€¢ Why Your Team Doesn\\'t Trust AI and How You Can Change It by Sjoerd. \\r\\nCTO Office \\r\\nAs you all know, we have been hiring for a new role with Xebia Data: the Field CTO \\r\\nrole. The Field CTO will focus on engaging with clients, providing architectural \\r\\nguidance, and supporting our sales team in presales activities.\\r\\nWe are happy to announce the first group of Field CTOs:\\r\\nâ€¢ Cor Zuurmond \\r\\nâ€¢ Jasper Ginn \\r\\nâ€¢ Julian de Ruiter \\r\\nâ€¢ Padraic Slattery \\r\\nâ€¢ Rogier van der Geer \\r\\nPadraic Slattery will be leading the group with my support. Once the group has \\r\\nsettled in, we will be hosting an XKE to discuss how the Field CTO role is being filled, \\r\\nthe initial challenges we encountered, and any other learnings.\\r\\nWe wish the group well in their new role, good luck!\\r\\nMotherduck update \\r\\nWe are happy to announce that we will be become a partner of Motherduck. \\r\\nMotherduck will launch the EU service next month and we will be included as an launching \\r\\npartner. Together with them we will host a webinar, create a blog post and start sharing \\r\\nopportunities. \\r\\nThanks to Tim W for managing the sales effort around the partnership! \\r\\nDatabricks update \\r\\nA general update for our Databricks partnership and a look forward to end of year. Thanks \\r\\nCor! \\r\\nWe have more traction with landing projects together or through Databricks. A new avenue \\r\\nto collaborate is the DPP program. Colleagues that get onboarded through the program can \\r\\nbe selected by Databricks to help their customers. \\r\\nThere are various specializations and levels, from Data Engineering to AI/ML, from \\r\\nArchitects to Solution Consultants. Currently, Databricks is asking us to propose Sr. GenAI \\r\\nEngineers, and Caio have started the interview process.\"\n",
      "      page_span {\n",
      "        first_page: 10\n",
      "        last_page: 10\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    source_uri: \"gs://rag-corpus-bing/documents/2400_3_1249969_1759839680_Databricks - Generic.pdf\"\n",
      "    text: \"Bing Tan\\r\\nMachine Learning Operations\\r\\n 10/7/2025\\r\\n \\r\\n \\r\\nPowered by TCPDF (www.tcpdf.org)\"\n",
      "    source_display_name: \"2400_3_1249969_1759839680_Databricks - Generic.pdf\"\n",
      "    score: 0.38412193332087985\n",
      "    chunk {\n",
      "      text: \"Bing Tan\\r\\nMachine Learning Operations\\r\\n 10/7/2025\\r\\n \\r\\n \\r\\nPowered by TCPDF (www.tcpdf.org)\"\n",
      "      page_span {\n",
      "        first_page: 1\n",
      "        last_page: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bing/.pyenv/versions/3.10.18/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "E0000 00:00:1760531642.417863 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760531642.420945 2579195 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Tan is certified in Machine Learning Operations by Databricks Academy. Xebia has 83 certified colleagues.\n"
     ]
    }
   ],
   "source": [
    "from vertexai import rag\n",
    "from vertexai.generative_models import GenerativeModel, Tool\n",
    "import vertexai\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"\"\n",
    "os.environ[\"GRPC_TRACE\"] = \"\"\n",
    "\n",
    "# Create a RAG Corpus, Import Files, and Generate a response\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "PROJECT_ID = \"bing-tan-sndbx-c\"\n",
    "display_name = \"personal-documents\"\n",
    "paths = [\"gs://rag-corpus-bing/documents\"]  # Supports Google Cloud Storage and Google Drive Links\n",
    "\n",
    "# Initialize Vertex AI API once per session\n",
    "vertexai.init(project=PROJECT_ID, location=\"europe-west4\")\n",
    "\n",
    "# Create RagCorpus\n",
    "# Configure embedding model, for example \"text-embedding-005\".\n",
    "embedding_model_config = rag.RagEmbeddingModelConfig(\n",
    "    vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
    "        publisher_model=\"publishers/google/models/text-embedding-005\"\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_corpus = rag.get_corpus(name=\"projects/bing-tan-sndbx-c/locations/europe-west4/ragCorpora/6917529027641081856\")\n",
    "\n",
    "\n",
    "# Import Files to the RagCorpus\n",
    "rag.import_files(\n",
    "    rag_corpus.name,\n",
    "    paths,\n",
    "    # Optional\n",
    "    transformation_config=rag.TransformationConfig(\n",
    "        chunking_config=rag.ChunkingConfig(\n",
    "            chunk_size=512,\n",
    "            chunk_overlap=100,\n",
    "        ),\n",
    "    ),\n",
    "    max_embedding_requests_per_min=1000,  # Optional\n",
    ")\n",
    "\n",
    "# Direct context retrieval\n",
    "rag_retrieval_config = rag.RagRetrievalConfig(\n",
    "    top_k=3,  # Optional\n",
    "    filter=rag.Filter(vector_distance_threshold=0.5),  # Optional\n",
    ")\n",
    "response = rag.retrieval_query(\n",
    "    rag_resources=[\n",
    "        rag.RagResource(\n",
    "            rag_corpus=rag_corpus.name,\n",
    "            # Optional: supply IDs from `rag.list_files()`.\n",
    "            # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "        )\n",
    "    ],\n",
    "    text=\"Tell me who is databricks academy ml ops certified?\",\n",
    "    rag_retrieval_config=rag_retrieval_config,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "\n",
    "# Enhance generation\n",
    "# Create a RAG retrieval tool\n",
    "rag_retrieval_tool = Tool.from_retrieval(\n",
    "    retrieval=rag.Retrieval(\n",
    "        source=rag.VertexRagStore(\n",
    "            rag_resources=[\n",
    "                rag.RagResource(\n",
    "                    rag_corpus=rag_corpus.name,  # Currently only 1 corpus is allowed.\n",
    "                    # Optional: supply IDs from `rag.list_files()`.\n",
    "                    # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "                )\n",
    "            ],\n",
    "            rag_retrieval_config=rag_retrieval_config,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a Gemini model instance\n",
    "rag_model = GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-001\", tools=[rag_retrieval_tool]\n",
    ")\n",
    "\n",
    "# Generate response\n",
    "response = rag_model.generate_content(\"Tell me who is databricks academy ml ops certified?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fb84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
