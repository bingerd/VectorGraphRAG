{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9660ab1",
   "metadata": {},
   "source": [
    "## 🧩 Data Preprocessing for Ingestion Simulation\n",
    "\n",
    "In this stage, we preprocess the *All the News* dataset into structured, day-based partitions.  \n",
    "The goal is to simulate a **real-world data ingestion pipeline** for downstream document storage in **Qdrant** (for vector retrieval) and **Neo4j** (for graph relationships).\n",
    "\n",
    "### 🎯 Objectives\n",
    "- **Normalize** textual data by removing excessive whitespace and line breaks to reduce storage bloat.  \n",
    "- **Parse and validate** publication dates into a consistent datetime format.  \n",
    "- **Partition** data efficiently by day to mimic incremental ingestion batches.  \n",
    "- **Prepare** clean CSV outputs for each day to serve as ingestion-ready artifacts.\n",
    "\n",
    "### ⚙️ Workflow\n",
    "1. **Load & filter** only the relevant columns:  \n",
    "   `date, year, month, day, author, title, article, url, section, publication`  \n",
    "2. **Sanitize** text columns (`article`, `title`, `author`) by collapsing multi-line text into single lines.  \n",
    "3. **Convert** date strings into proper datetime objects, extracting the date component.  \n",
    "4. **Group and write** records into per-day CSV partitions under the `data/` directory.\n",
    "\n",
    "Each output file represents a realistic **daily ingestion batch**, allowing us to later simulate:\n",
    "- Vector embedding creation and storage in **Qdrant**\n",
    "- Knowledge graph linking in **Neo4j**\n",
    "- Continuous **RAG pipeline evaluation**\n",
    "\n",
    "This modular preprocessing design mirrors how production pipelines would handle incoming text streams in real-world ML or data engineering systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15b10f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688879, 10)\n",
      "shape: (5, 10)\n",
      "┌───────────────┬──────┬───────┬─────┬───┬──────────────┬──────────────┬────────────┬──────────────┐\n",
      "│ date          ┆ year ┆ month ┆ day ┆ … ┆ article      ┆ url          ┆ section    ┆ publication  │\n",
      "│ ---           ┆ ---  ┆ ---   ┆ --- ┆   ┆ ---          ┆ ---          ┆ ---        ┆ ---          │\n",
      "│ datetime[μs]  ┆ i64  ┆ f64   ┆ i64 ┆   ┆ str          ┆ str          ┆ str        ┆ str          │\n",
      "╞═══════════════╪══════╪═══════╪═════╪═══╪══════════════╪══════════════╪════════════╪══════════════╡\n",
      "│ 2016-12-09    ┆ 2016 ┆ 12.0  ┆ 9   ┆ … ┆ This post is ┆ https://www. ┆ null       ┆ Vox          │\n",
      "│ 18:31:00      ┆      ┆       ┆     ┆   ┆ part of      ┆ vox.com/poly ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ Polyarchy…   ┆ archy/…      ┆            ┆              │\n",
      "│ 2016-10-07    ┆ 2016 ┆ 10.0  ┆ 7   ┆ … ┆ The          ┆ https://www. ┆ null       ┆ Business     │\n",
      "│ 21:26:46      ┆      ┆       ┆     ┆   ┆ Indianapolis ┆ businessinsi ┆            ┆ Insider      │\n",
      "│               ┆      ┆       ┆     ┆   ┆ Colts made   ┆ der.co…      ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ A…           ┆              ┆            ┆              │\n",
      "│ 2018-01-26    ┆ 2018 ┆ 1.0   ┆ 26  ┆ … ┆ DAVOS,       ┆ https://www. ┆ Davos      ┆ Reuters      │\n",
      "│ 00:00:00      ┆      ┆       ┆     ┆   ┆ Switzerland  ┆ reuters.com/ ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ (Reuters) -… ┆ articl…      ┆            ┆              │\n",
      "│ 2019-06-27    ┆ 2019 ┆ 6.0   ┆ 27  ┆ … ┆ PARIS        ┆ https://www. ┆ World News ┆ Reuters      │\n",
      "│ 00:00:00      ┆      ┆       ┆     ┆   ┆ (Reuters) -  ┆ reuters.com/ ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ Former       ┆ articl…      ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ Frenc…       ┆              ┆            ┆              │\n",
      "│ 2016-01-27    ┆ 2016 ┆ 1.0   ┆ 27  ┆ … ┆ Paris Hilton ┆ https://www. ┆ null       ┆ TMZ          │\n",
      "│ 00:00:00      ┆      ┆       ┆     ┆   ┆ arrived at   ┆ tmz.com/2016 ┆            ┆              │\n",
      "│               ┆      ┆       ┆     ┆   ┆ LAX We…      ┆ /01/27…      ┆            ┆              │\n",
      "└───────────────┴──────┴───────┴─────┴───┴──────────────┴──────────────┴────────────┴──────────────┘\n",
      "Error processing day None: 'NoneType' object has no attribute 'isoformat', chunk size: 1\n",
      "✅ Total articles processed: 2688878\n",
      "✅ Total days partitioned: 1555\n",
      "✅ Partitioning 100.00% complete.\n",
      "🗂️ Partitioned files saved under: /Users/bing/Repositories/KG VectorDB RAG/data\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from kagglehub import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Setup paths ---\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"davidmckinley/all-the-news-dataset\")\n",
    "csv_file = Path(path) / \"all-the-news-2-1.csv\"\n",
    "\n",
    "# Resolve base paths\n",
    "base_dir = Path(__file__).resolve().parent if \"__file__\" in locals() else Path.cwd()\n",
    "project_root = base_dir.parent\n",
    "data_path = project_root / \"data\"\n",
    "\n",
    "data_path.mkdir(parents=True, exist_ok=True)  # ensure data directory exists\n",
    "\n",
    "use_columns = [\n",
    "    \"date\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"author\",\n",
    "    \"title\",\n",
    "    \"article\",\n",
    "    \"url\",\n",
    "    \"section\",\n",
    "    \"publication\"\n",
    "]\n",
    "# --- Load data ---\n",
    "df = pl.read_csv(\n",
    "    csv_file, \n",
    "    columns=use_columns,\n",
    "    infer_schema_length=100000,\n",
    "    ignore_errors=True,\n",
    "    try_parse_dates=True,\n",
    "    null_values=[\"\", \"NA\", \"NULL\"]\n",
    "    )\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df = df.with_columns(pl.col(\"date\").dt.date().alias(\"day\"))\n",
    "\n",
    "# --- Partition by day into data folder ---\n",
    "sum_articles = 0\n",
    "for day, daily_chunk in df.group_by(\"day\"):\n",
    "    try:\n",
    "        # each day gets its own subfolder inside data/\n",
    "        output_dir = data_path / f\"{day[0].isoformat()}\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        daily_chunk = daily_chunk.with_columns([\n",
    "            pl.col(\"article\").str.replace_all(r\"\\s+\", \" \").alias(\"article\"),\n",
    "            pl.col(\"title\").str.replace_all(r\"\\s+\", \" \").alias(\"title\"),\n",
    "            pl.col(\"author\").str.replace_all(r\"\\s+\", \" \").alias(\"author\"),\n",
    "        ])\n",
    "\n",
    "        # write the partition\n",
    "        daily_chunk.write_csv(output_dir / f\"news_articles_{len(daily_chunk)}.csv\")\n",
    "        sum_articles += len(daily_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing day {day[0]}: {e}, chunk size: {len(daily_chunk)}\")\n",
    "\n",
    "print(f\"✅ Total articles processed: {sum_articles}\")\n",
    "print(f\"✅ Total days partitioned: {len(df.select('day').unique())}\")\n",
    "print(f\"✅ Partitioning {sum_articles/df.shape[0]:.2%} complete.\")\n",
    "print(f\"🗂️ Partitioned files saved under: {data_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcba13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
